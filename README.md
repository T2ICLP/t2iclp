# T2ICLP dataset
### Project Profile
  This repository is used for presentations on the T2ICLP dataset.Here, we have uploaded 50 images within the T2ICLP dataset, along with the corresponding text descriptions.
### FHS-Adapter
In recent years, denoising diffusion models have performed well on the task of generating images from generalized text. However, on the task of generating images from text in specific art domains, such as Chinese landscape painting, the images generated by existing methods are less effective in the evaluation dimensions such as mood expression, cultural characteristics, and brush and ink techniques, due to the quantity and quality of the dataset. In order to impose constraints in the diffusion process and incorporate specific background information to give stronger features to the generated images, this study proposes a mask feature prediction and segmentation map-guided wen-geng-mu method called FSM-Adapter. The method first draws on the four kinds of textual background information (history and culture, picture content, emotion and poetry) of the paintings, which are structurally integrated into the pre-trained Stable Diffusion model as a supplementary knowledge hierarchy to enrich the semantic information of the generated content. Secondly, the segmentation map is utilized as additional visual information to guide the generation process through the SegControl module in order to accurately generate layout and composition elements. Finally, the local and global feature embedding distances between the output image of the diffusion model and the real image are optimized by the mask self-encoder to achieve the detail adjustment constraints and global style constraints, which further improves the model's ability to capture and reproduce the subtle features of Chinese landscape paintings. The synergy of the three modules makes FSM-Adapter effectively improve the quality and expressiveness of text-generated images of Chinese landscape paintings. 
### code
Not available at this time. We will upload the training as well as the test code and the full dataset at an appropriate time!
